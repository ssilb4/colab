{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dacon_TabNet_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d36c797b39da4c73ae6672f4e6861d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edb0426be9ed46c78523403419f53c85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf97ae10dbde479fb43cdae93a338924",
              "IPY_MODEL_78a401eefe19402a83955c3373be7537"
            ]
          }
        },
        "edb0426be9ed46c78523403419f53c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf97ae10dbde479fb43cdae93a338924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_324e3c855bde41b7b5a25ef362386f5a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 18,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 18,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8bdf7a664b2470c87c4687b3d5c0ec5"
          }
        },
        "78a401eefe19402a83955c3373be7537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d745862494f4df997818349a3c6cfd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 18/18 [01:11&lt;00:00,  4.00s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2845e66b638d4d5ca0239dea7953c1c6"
          }
        },
        "324e3c855bde41b7b5a25ef362386f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8bdf7a664b2470c87c4687b3d5c0ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d745862494f4df997818349a3c6cfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2845e66b638d4d5ca0239dea7953c1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssilb4/colab/blob/master/dacon_TabNet_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiAPQM92twJ-",
        "outputId": "2100fd83-f786-42f4-af7e-6f5dd8b07ae2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27f82-Yetwm-",
        "outputId": "2af24da6-7653-4143-fcca-63fcf5447188"
      },
      "source": [
        "!pip uninstall -y typing # this should avoid  AttributeError: type object 'Callable' has no attribute '_abc_registry'\n",
        "\n",
        "!pip install  \"git+https://github.com/dreamquark-ai/tabnet.git@develop#egg=pytorch_tabnet\" --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping typing as it is not installed.\u001b[0m\n",
            "Collecting pytorch_tabnet\n",
            "  Cloning https://github.com/dreamquark-ai/tabnet.git (to revision develop) to /tmp/pip-install-9f1rg8bk/pytorch-tabnet\n",
            "  Running command git clone -q https://github.com/dreamquark-ai/tabnet.git /tmp/pip-install-9f1rg8bk/pytorch-tabnet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_tabnet) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch_tabnet) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-tabnet\n",
            "  Building wheel for pytorch-tabnet (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-tabnet: filename=pytorch_tabnet-3.1.1-cp37-none-any.whl size=39236 sha256=4130c9e3cd04d97c2e0d980c478e70f5e1cd5d2937b3e546a6f7517a46bbada2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dy27fsnm/wheels/a5/fe/e1/d7be493728d1fb7284583f5449d4cad80139ee994ef420f522\n",
            "Successfully built pytorch-tabnet\n",
            "Installing collected packages: pytorch-tabnet\n",
            "  Found existing installation: pytorch-tabnet 3.1.1\n",
            "    Uninstalling pytorch-tabnet-3.1.1:\n",
            "      Successfully uninstalled pytorch-tabnet-3.1.1\n",
            "Successfully installed pytorch-tabnet-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P14WWN1at_9I"
      },
      "source": [
        "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
        "\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBnLMy5dt3FN"
      },
      "source": [
        "path = '/content/drive/MyDrive/dacon/data/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SlkIiPbvXWd"
      },
      "source": [
        "train = pd.read_csv(path+'train.csv')\n",
        "train = train.drop(['index'], axis=1)\n",
        "train.fillna('NAN', inplace=True) \n",
        "\n",
        "\n",
        "test = pd.read_csv(path+'test.csv')\n",
        "test = test.drop(['index'], axis=1)\n",
        "test.fillna('NAN', inplace=True)\n",
        "\n",
        "submission = pd.read_csv(path+'sample_submission.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnmG9uSYt7VU",
        "outputId": "154feae6-76a1-47e8-fd6d-571a51fe1e45"
      },
      "source": [
        "data=pd.concat([train, test], axis=0)\n",
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36457, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj29r2ULt8pk"
      },
      "source": [
        "# 나이 변환\n",
        "def days_to_age(x):\n",
        "    return (x*-1)/365\n",
        "data['DAYS_BIRTH'] = data['DAYS_BIRTH'].apply(days_to_age)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3XixIZ3uJW8"
      },
      "source": [
        "# 마이너스 값 변환\n",
        "def minus(x):\n",
        "    return x * -1\n",
        "data['begin_month'] = data['begin_month'].apply(minus)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLm616Y2uKrM"
      },
      "source": [
        "data.loc[(data.DAYS_EMPLOYED)>=0,'DAYS_EMPLOYED'] = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5h9G1J4uMDE"
      },
      "source": [
        "#data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].apply(days_to_age)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Ayj54vuNH0"
      },
      "source": [
        "#data.loc[data['child_num'] >= 2,'child_num']=2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "88nAEKUtuOcs",
        "outputId": "fc307530-732b-44bf-81b0-b57b02159cc8"
      },
      "source": [
        "'''\n",
        "data['income_total'] = data['income_total'].astype(object)\n",
        "data['income_total'] = data['income_total']/10000 \n",
        "print(data['income_total'].value_counts(bins=10,sort=False))\n",
        "data['income_total'].plot(kind='hist',bins=50,density=True)\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndata['income_total'] = data['income_total'].astype(object)\\ndata['income_total'] = data['income_total']/10000 \\nprint(data['income_total'].value_counts(bins=10,sort=False))\\ndata['income_total'].plot(kind='hist',bins=50,density=True)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4faSWsruQw9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "77e904cb-baa0-46c6-aa2d-a2be104e501c"
      },
      "source": [
        "'''\n",
        "count, bin_dividers =np.histogram(data['income_total'], bins=7)\n",
        "bin_names=[int(i) for i in range(7) ]\n",
        "data['income_total']=pd.cut(x=data['income_total'], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ncount, bin_dividers =np.histogram(data['income_total'], bins=7)\\nbin_names=[int(i) for i in range(7) ]\\ndata['income_total']=pd.cut(x=data['income_total'], bins=bin_dividers, labels=bin_names, include_lowest=True)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZyJkhr64Y6T",
        "outputId": "4b3e67ea-47e6-49c8-a394-113782973acb"
      },
      "source": [
        "print(data[data['income_type'] == 'Pensioner'].info())\n",
        "data[data['income_type'] == 'Pensioner']['occyp_type'].unique()\n",
        "\n",
        "print(data[(data['income_type'] == 'Pensioner') & (data['occyp_type'].isnull())])\n",
        "\n",
        "data.loc[(data['income_type'] == 'Pensioner') & (data['occyp_type'].isnull()), 'occyp_type'] = 'no worker'\n",
        "\n",
        "data.isnull().sum()\n",
        "\n",
        "data[data['occyp_type'].isnull()]['income_type'].unique()\n",
        "\n",
        "data['occyp_type'].unique()\n",
        "\n",
        "print(data[data['occyp_type'] == 'Laborers']['income_type'].unique())\n",
        "print(data[data['occyp_type'] == 'Low-skill Laborers']['income_type'].unique())\n",
        "print(data[data['occyp_type'] == 'Managers']['income_type'].unique())\n",
        "\n",
        "print(data[data['income_type'] == 'Commercial associate']['occyp_type'].describe())\n",
        "data.loc[data['income_type'] == 'Commercial associate', 'occyp_type'] = 'Laborers'\n",
        "\n",
        "print(data[data['income_type'] == 'Working']['occyp_type'].describe())\n",
        "data.loc[data['income_type'] == 'Working', 'occyp_type'] = 'Laborers'\n",
        "\n",
        "print(data[data['income_type'] == 'State servant']['occyp_type'].describe())\n",
        "data.loc[data['income_type'] == 'State servant', 'occyp_type'] = 'Core staff'\n",
        "\n",
        "print(data[data['income_type'] == 'Student']['occyp_type'].describe())\n",
        "data.loc[data['income_type'] == 'Student', 'occyp_type'] = 'no worker'\n",
        "\n",
        "data.isnull().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6152 entries, 14 to 9994\n",
            "Data columns (total 19 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   gender         6152 non-null   object \n",
            " 1   car            6152 non-null   object \n",
            " 2   reality        6152 non-null   object \n",
            " 3   child_num      6152 non-null   int64  \n",
            " 4   income_total   6152 non-null   float64\n",
            " 5   income_type    6152 non-null   object \n",
            " 6   edu_type       6152 non-null   object \n",
            " 7   family_type    6152 non-null   object \n",
            " 8   house_type     6152 non-null   object \n",
            " 9   DAYS_BIRTH     6152 non-null   float64\n",
            " 10  DAYS_EMPLOYED  6152 non-null   int64  \n",
            " 11  FLAG_MOBIL     6152 non-null   int64  \n",
            " 12  work_phone     6152 non-null   int64  \n",
            " 13  phone          6152 non-null   int64  \n",
            " 14  email          6152 non-null   int64  \n",
            " 15  occyp_type     6152 non-null   object \n",
            " 16  family_size    6152 non-null   float64\n",
            " 17  begin_month    6152 non-null   float64\n",
            " 18  credit         4449 non-null   float64\n",
            "dtypes: float64(5), int64(6), object(8)\n",
            "memory usage: 961.2+ KB\n",
            "None\n",
            "Empty DataFrame\n",
            "Columns: [gender, car, reality, child_num, income_total, income_type, edu_type, family_type, house_type, DAYS_BIRTH, DAYS_EMPLOYED, FLAG_MOBIL, work_phone, phone, email, occyp_type, family_size, begin_month, credit]\n",
            "Index: []\n",
            "['Commercial associate' 'Working' 'State servant' 'Pensioner' 'Student']\n",
            "['Working' 'Commercial associate' 'State servant' 'Pensioner']\n",
            "['Working' 'State servant' 'Commercial associate' 'Pensioner']\n",
            "count         8490\n",
            "unique          19\n",
            "top       Laborers\n",
            "freq          1461\n",
            "Name: occyp_type, dtype: object\n",
            "count        18819\n",
            "unique          19\n",
            "top       Laborers\n",
            "freq          4553\n",
            "Name: occyp_type, dtype: object\n",
            "count           2985\n",
            "unique            18\n",
            "top       Core staff\n",
            "freq             900\n",
            "Name: occyp_type, dtype: object\n",
            "count             11\n",
            "unique             3\n",
            "top       Core staff\n",
            "freq               8\n",
            "Name: occyp_type, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender               0\n",
              "car                  0\n",
              "reality              0\n",
              "child_num            0\n",
              "income_total         0\n",
              "income_type          0\n",
              "edu_type             0\n",
              "family_type          0\n",
              "house_type           0\n",
              "DAYS_BIRTH           0\n",
              "DAYS_EMPLOYED        0\n",
              "FLAG_MOBIL           0\n",
              "work_phone           0\n",
              "phone                0\n",
              "email                0\n",
              "occyp_type           0\n",
              "family_size          0\n",
              "begin_month          0\n",
              "credit           10000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9wawF9GullZ",
        "outputId": "cc9b9a36-cd2e-43f0-da6f-324152524fd7"
      },
      "source": [
        "data['gender'] = data['gender'].replace(['F','M'],[0,1])\n",
        "print('gender :')\n",
        "print(data['gender'].value_counts())\n",
        "print('--------------')\n",
        "\n",
        "print('Having a car or not : ')\n",
        "data['car'] = data['car'].replace(['N','Y'],[0,1])\n",
        "print(data['car'].value_counts())\n",
        "print('--------------')\n",
        "\n",
        "print('Having house reality or not: ')\n",
        "data['reality'] = data['reality'].replace(['N','Y'],[0,1])\n",
        "print(data['reality'].value_counts())\n",
        "print('--------------')\n",
        "      \n",
        "print('Having a phone or not: ')\n",
        "print(data['phone'].value_counts())\n",
        "print('--------------')\n",
        "      \n",
        "\n",
        "print('Having a email or not: ')\n",
        "print(data['email'].value_counts())\n",
        "print('--------------')\n",
        "      \n",
        "\n",
        "print('Having a work phone or not: ')\n",
        "print(data['work_phone'].value_counts())\n",
        "print('--------------')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender :\n",
            "0    24430\n",
            "1    12027\n",
            "Name: gender, dtype: int64\n",
            "--------------\n",
            "Having a car or not : \n",
            "0    22614\n",
            "1    13843\n",
            "Name: car, dtype: int64\n",
            "--------------\n",
            "Having house reality or not: \n",
            "1    24506\n",
            "0    11951\n",
            "Name: reality, dtype: int64\n",
            "--------------\n",
            "Having a phone or not: \n",
            "0    25709\n",
            "1    10748\n",
            "Name: phone, dtype: int64\n",
            "--------------\n",
            "Having a email or not: \n",
            "0    33186\n",
            "1     3271\n",
            "Name: email, dtype: int64\n",
            "--------------\n",
            "Having a work phone or not: \n",
            "0    28235\n",
            "1     8222\n",
            "Name: work_phone, dtype: int64\n",
            "--------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS4FEd6_uqlE"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "label_encoder=preprocessing.LabelEncoder()\n",
        "data['income_type']=label_encoder.fit_transform(data['income_type'])\n",
        "data['edu_type']=label_encoder.fit_transform(data['edu_type'])\n",
        "data['family_type']=label_encoder.fit_transform(data['family_type'])\n",
        "data['house_type']=label_encoder.fit_transform(data['house_type'])\n",
        "data['income_total']=label_encoder.fit_transform(data['income_total'])\n",
        "data['occyp_type']=label_encoder.fit_transform(data['occyp_type'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5koZKwnOvf5_",
        "outputId": "53d49d05-8357-4396-c1be-a3d6515dae5f"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 36457 entries, 0 to 9999\n",
            "Data columns (total 19 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   gender         36457 non-null  int64  \n",
            " 1   car            36457 non-null  int64  \n",
            " 2   reality        36457 non-null  int64  \n",
            " 3   child_num      36457 non-null  int64  \n",
            " 4   income_total   36457 non-null  int64  \n",
            " 5   income_type    36457 non-null  int64  \n",
            " 6   edu_type       36457 non-null  int64  \n",
            " 7   family_type    36457 non-null  int64  \n",
            " 8   house_type     36457 non-null  int64  \n",
            " 9   DAYS_BIRTH     36457 non-null  float64\n",
            " 10  DAYS_EMPLOYED  36457 non-null  int64  \n",
            " 11  FLAG_MOBIL     36457 non-null  int64  \n",
            " 12  work_phone     36457 non-null  int64  \n",
            " 13  phone          36457 non-null  int64  \n",
            " 14  email          36457 non-null  int64  \n",
            " 15  occyp_type     36457 non-null  int64  \n",
            " 16  family_size    36457 non-null  float64\n",
            " 17  begin_month    36457 non-null  float64\n",
            " 18  credit         26457 non-null  float64\n",
            "dtypes: float64(4), int64(15)\n",
            "memory usage: 5.6 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_O7Gpb3uSMU"
      },
      "source": [
        "train=data[:len(data)-10000]\n",
        "test=data[len(data)-10000:]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3UMfI_Tue8E"
      },
      "source": [
        "train_x=train.drop('credit', axis=1)\n",
        "train_y=train[['credit']]\n",
        "test_x=test.drop('credit', axis=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0d3R_Scx7GO",
        "outputId": "c08f9572-1184-4f83-b6bf-dd41c0efd87c"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import OneSidedSelection\n",
        "\n",
        "train_x, train_y = OneSidedSelection(random_state=1).fit_sample(train_x, train_y)\n",
        "train_x, train_y = SMOTE(random_state=1).fit_sample(train_x, train_y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJQwpYaN0aBy",
        "outputId": "aa4decc8-ed83-44a0-b63a-accf45c6fd7d"
      },
      "source": [
        "train.columns.drop('credit')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['gender', 'car', 'reality', 'child_num', 'income_total', 'income_type',\n",
              "       'edu_type', 'family_type', 'house_type', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
              "       'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type',\n",
              "       'family_size', 'begin_month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDwTTrgFztXW"
      },
      "source": [
        "train_x = pd.DataFrame(train_x, columns = train.columns.drop('credit'))\n",
        "train_y = pd.DataFrame(train_y, columns = ['credit'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXfdpJmfv5yO"
      },
      "source": [
        "np.random.seed(42)\n",
        "if \"Set\" not in train_x.columns:\n",
        "    train_x[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.8, .2], size=(train_x.shape[0],))\n",
        "\n",
        "train_indices = train_x[train_x.Set==\"train\"].index\n",
        "valid_indices = train_x[train_x.Set==\"valid\"].index"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH9QxjSaz3sc",
        "outputId": "5db92247-71b3-40c0-a002-bd1ce3bad5be"
      },
      "source": [
        "train_x"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        2213\n",
              "1        2213\n",
              "2        2213\n",
              "3        2213\n",
              "4        2213\n",
              "         ... \n",
              "44995    2213\n",
              "44996       1\n",
              "44997    1185\n",
              "44998    2213\n",
              "44999    2213\n",
              "Name: occyp_type, Length: 45000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btt4H-dy3pjq",
        "outputId": "91973a12-f1c2-46f9-ba37-046cf0b0e90a"
      },
      "source": [
        "test_x"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       7\n",
              "1       1\n",
              "2       3\n",
              "3       3\n",
              "4       1\n",
              "       ..\n",
              "9995    3\n",
              "9996    3\n",
              "9997    3\n",
              "9998    3\n",
              "9999    3\n",
              "Name: occyp_type, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "d36c797b39da4c73ae6672f4e6861d2a",
            "edb0426be9ed46c78523403419f53c85",
            "cf97ae10dbde479fb43cdae93a338924",
            "78a401eefe19402a83955c3373be7537",
            "324e3c855bde41b7b5a25ef362386f5a",
            "b8bdf7a664b2470c87c4687b3d5c0ec5",
            "5d745862494f4df997818349a3c6cfd6",
            "2845e66b638d4d5ca0239dea7953c1c6"
          ]
        },
        "id": "em0mmywXvx7X",
        "outputId": "867f3e64-7c27-4ff2-ef94-caf8e7e4740f"
      },
      "source": [
        "\n",
        "nunique = train.nunique()\n",
        "types = train.dtypes\n",
        "\n",
        "categorical_columns = []\n",
        "categorical_dims =  {}\n",
        "for col in tqdm(train_x.columns.drop('Set')):\n",
        "    if types[col] == 'object' or nunique[col] < 200:\n",
        "        print(col, train_x[col].nunique())\n",
        "        l_enc = LabelEncoder()\n",
        "        train_x[col] = train_x[col].fillna(\"NaN\")\n",
        "        train_x[col] = l_enc.fit_transform(train_x[col].values)\n",
        "        try:\n",
        "            test_x[col] = test_x[col].fillna(\"NaN\")\n",
        "            test_x[col] = l_enc.transform(test_x[col].values)\n",
        "        except:\n",
        "            print(f\"Column {col} does not exist in test set\")\n",
        "        categorical_columns.append(col)\n",
        "        categorical_dims[col] = len(l_enc.classes_)\n",
        "    else:\n",
        "        training_mean = train_x.loc[train_indices, col].mean()\n",
        "        train.fillna(training_mean, inplace=True)\n",
        "        test.fillna(training_mean, inplace=True)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d36c797b39da4c73ae6672f4e6861d2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "gender 6585\n",
            "car 6803\n",
            "reality 7022\n",
            "child_num 6859\n",
            "income_type 6568\n",
            "edu_type 7054\n",
            "family_type 8196\n",
            "house_type 3271\n",
            "FLAG_MOBIL 1\n",
            "work_phone 5123\n",
            "phone 6798\n",
            "email 2489\n",
            "occyp_type 2228\n",
            "Column occyp_type does not exist in test set\n",
            "family_size 9911\n",
            "begin_month 20655\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLDIXrqb526B",
        "outputId": "f10d3956-e21e-4332-ed57-af9fe16bf651"
      },
      "source": [
        "print(train_x)\n",
        "print(test_x)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       gender   car  reality  ...  family_size  begin_month    Set\n",
            "0           0     0     7021  ...         4065        16349  train\n",
            "1        6584     0     7021  ...         4065        20060  valid\n",
            "2           0  6802     7021  ...         8226        20654  train\n",
            "3        6584  6802     7021  ...         9682        20654  train\n",
            "4           0     0        0  ...         4065        11274  train\n",
            "...       ...   ...      ...  ...          ...          ...    ...\n",
            "44995       0     0        0  ...         4065        11641  train\n",
            "44996       0     0        0  ...         9682        18790  train\n",
            "44997    2992  3076     7021  ...         1826        17048  train\n",
            "44998    6584  6802     7021  ...         9306         4116  train\n",
            "44999       0  4978     5110  ...         8594          312  valid\n",
            "\n",
            "[45000 rows x 19 columns]\n",
            "      gender   car  reality  ...  occyp_type  family_size  begin_month\n",
            "0       6584  6802        0  ...           7         4065        20654\n",
            "1          0     0     7021  ...           1         4065        16029\n",
            "2          0     0     7021  ...           3         4065        17262\n",
            "3       6584  6802        0  ...           3         4065        17552\n",
            "4          0  6802     7021  ...           1         4065         4994\n",
            "...      ...   ...      ...  ...         ...          ...          ...\n",
            "9995       0  6802     7021  ...           3         4065        10087\n",
            "9996    6584  6802     7021  ...           3         4065        15401\n",
            "9997       0     0     7021  ...           3         4065        20297\n",
            "9998       0  6802        0  ...           3         4065        15098\n",
            "9999       0     0     7021  ...           3         4065         6451\n",
            "\n",
            "[10000 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKTrB147utgF"
      },
      "source": [
        "features = [ col for col in train_x.columns.drop('Set')] \n",
        "\n",
        "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUaJYaTzwA7q"
      },
      "source": [
        "X_train = train_x[features].values[train_indices]\n",
        "y_train = train_y.values[train_indices]\n",
        "\n",
        "X_valid = train_x[features].values[valid_indices]\n",
        "y_valid = train_y.values[valid_indices]\n",
        "\n",
        "X_test = test_x[features].values"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23dEgBqawEE0",
        "outputId": "83c23997-4ccc-451c-8e0c-1ed074971a6f"
      },
      "source": [
        "clf = TabNetMultiTaskClassifier(n_steps=1,\n",
        "                                cat_idxs=cat_idxs,\n",
        "                                cat_dims=cat_dims,\n",
        "                                cat_emb_dim=1,\n",
        "                                optimizer_fn=torch.optim.Adam,\n",
        "                                optimizer_params=dict(lr=2e-2),\n",
        "                                scheduler_params={\"step_size\":50,\n",
        "                                                  \"gamma\":0.9},\n",
        "                                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "                                mask_type='entmax', \n",
        "                                lambda_sparse=0, \n",
        "                       \n",
        "                      )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8WJjHC2tSP"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdjdntBmw7B0",
        "outputId": "b6205ba5-0112-4932-8493-fd49ea811834"
      },
      "source": [
        "max_epochs = 1000\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    max_epochs=max_epochs ,\n",
        "    patience=50, # please be patient ^^\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=1,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No early stopping will be performed, last training weights will be used.\n",
            "epoch 0  | loss: 1.02497 |  0:00:01s\n",
            "epoch 1  | loss: 0.91127 |  0:00:02s\n",
            "epoch 2  | loss: 0.83778 |  0:00:03s\n",
            "epoch 3  | loss: 0.77551 |  0:00:05s\n",
            "epoch 4  | loss: 0.75016 |  0:00:06s\n",
            "epoch 5  | loss: 0.72322 |  0:00:07s\n",
            "epoch 6  | loss: 0.68825 |  0:00:08s\n",
            "epoch 7  | loss: 0.6513  |  0:00:10s\n",
            "epoch 8  | loss: 0.60269 |  0:00:11s\n",
            "epoch 9  | loss: 0.57221 |  0:00:12s\n",
            "epoch 10 | loss: 0.54832 |  0:00:14s\n",
            "epoch 11 | loss: 0.53182 |  0:00:15s\n",
            "epoch 12 | loss: 0.51854 |  0:00:16s\n",
            "epoch 13 | loss: 0.50676 |  0:00:17s\n",
            "epoch 14 | loss: 0.49948 |  0:00:19s\n",
            "epoch 15 | loss: 0.49353 |  0:00:20s\n",
            "epoch 16 | loss: 0.48422 |  0:00:21s\n",
            "epoch 17 | loss: 0.48485 |  0:00:22s\n",
            "epoch 18 | loss: 0.481   |  0:00:24s\n",
            "epoch 19 | loss: 0.49348 |  0:00:25s\n",
            "epoch 20 | loss: 0.48535 |  0:00:26s\n",
            "epoch 21 | loss: 0.48094 |  0:00:27s\n",
            "epoch 22 | loss: 0.47331 |  0:00:29s\n",
            "epoch 23 | loss: 0.46757 |  0:00:30s\n",
            "epoch 24 | loss: 0.4662  |  0:00:31s\n",
            "epoch 25 | loss: 0.46729 |  0:00:32s\n",
            "epoch 26 | loss: 0.46331 |  0:00:34s\n",
            "epoch 27 | loss: 0.46081 |  0:00:35s\n",
            "epoch 28 | loss: 0.45988 |  0:00:36s\n",
            "epoch 29 | loss: 0.45549 |  0:00:37s\n",
            "epoch 30 | loss: 0.45379 |  0:00:39s\n",
            "epoch 31 | loss: 0.45844 |  0:00:40s\n",
            "epoch 32 | loss: 0.45638 |  0:00:41s\n",
            "epoch 33 | loss: 0.4633  |  0:00:42s\n",
            "epoch 34 | loss: 0.45569 |  0:00:44s\n",
            "epoch 35 | loss: 0.45135 |  0:00:45s\n",
            "epoch 36 | loss: 0.45086 |  0:00:46s\n",
            "epoch 37 | loss: 0.45691 |  0:00:47s\n",
            "epoch 38 | loss: 0.44795 |  0:00:49s\n",
            "epoch 39 | loss: 0.44358 |  0:00:50s\n",
            "epoch 40 | loss: 0.44173 |  0:00:51s\n",
            "epoch 41 | loss: 0.44302 |  0:00:52s\n",
            "epoch 42 | loss: 0.44022 |  0:00:54s\n",
            "epoch 43 | loss: 0.44492 |  0:00:55s\n",
            "epoch 44 | loss: 0.43991 |  0:00:56s\n",
            "epoch 45 | loss: 0.44116 |  0:00:57s\n",
            "epoch 46 | loss: 0.43826 |  0:00:59s\n",
            "epoch 47 | loss: 0.43718 |  0:01:00s\n",
            "epoch 48 | loss: 0.43787 |  0:01:01s\n",
            "epoch 49 | loss: 0.43935 |  0:01:02s\n",
            "epoch 50 | loss: 0.44017 |  0:01:04s\n",
            "epoch 51 | loss: 0.44377 |  0:01:05s\n",
            "epoch 52 | loss: 0.44391 |  0:01:06s\n",
            "epoch 53 | loss: 0.43792 |  0:01:07s\n",
            "epoch 54 | loss: 0.43586 |  0:01:09s\n",
            "epoch 55 | loss: 0.43661 |  0:01:10s\n",
            "epoch 56 | loss: 0.43632 |  0:01:11s\n",
            "epoch 57 | loss: 0.43718 |  0:01:12s\n",
            "epoch 58 | loss: 0.43452 |  0:01:14s\n",
            "epoch 59 | loss: 0.4349  |  0:01:15s\n",
            "epoch 60 | loss: 0.43374 |  0:01:16s\n",
            "epoch 61 | loss: 0.43265 |  0:01:17s\n",
            "epoch 62 | loss: 0.43428 |  0:01:19s\n",
            "epoch 63 | loss: 0.43808 |  0:01:20s\n",
            "epoch 64 | loss: 0.4346  |  0:01:21s\n",
            "epoch 65 | loss: 0.43264 |  0:01:22s\n",
            "epoch 66 | loss: 0.43792 |  0:01:23s\n",
            "epoch 67 | loss: 0.43556 |  0:01:25s\n",
            "epoch 68 | loss: 0.43621 |  0:01:26s\n",
            "epoch 69 | loss: 0.43305 |  0:01:27s\n",
            "epoch 70 | loss: 0.43201 |  0:01:29s\n",
            "epoch 71 | loss: 0.43291 |  0:01:30s\n",
            "epoch 72 | loss: 0.43225 |  0:01:31s\n",
            "epoch 73 | loss: 0.43135 |  0:01:32s\n",
            "epoch 74 | loss: 0.43087 |  0:01:33s\n",
            "epoch 75 | loss: 0.43086 |  0:01:35s\n",
            "epoch 76 | loss: 0.43539 |  0:01:36s\n",
            "epoch 77 | loss: 0.43235 |  0:01:37s\n",
            "epoch 78 | loss: 0.43101 |  0:01:39s\n",
            "epoch 79 | loss: 0.43157 |  0:01:40s\n",
            "epoch 80 | loss: 0.43318 |  0:01:41s\n",
            "epoch 81 | loss: 0.43504 |  0:01:42s\n",
            "epoch 82 | loss: 0.43422 |  0:01:44s\n",
            "epoch 83 | loss: 0.43208 |  0:01:45s\n",
            "epoch 84 | loss: 0.43164 |  0:01:46s\n",
            "epoch 85 | loss: 0.43161 |  0:01:47s\n",
            "epoch 86 | loss: 0.43155 |  0:01:49s\n",
            "epoch 87 | loss: 0.43039 |  0:01:50s\n",
            "epoch 88 | loss: 0.43167 |  0:01:51s\n",
            "epoch 89 | loss: 0.4317  |  0:01:52s\n",
            "epoch 90 | loss: 0.43006 |  0:01:54s\n",
            "epoch 91 | loss: 0.43024 |  0:01:55s\n",
            "epoch 92 | loss: 0.4308  |  0:01:56s\n",
            "epoch 93 | loss: 0.43419 |  0:01:57s\n",
            "epoch 94 | loss: 0.43745 |  0:01:59s\n",
            "epoch 95 | loss: 0.43441 |  0:02:00s\n",
            "epoch 96 | loss: 0.43398 |  0:02:01s\n",
            "epoch 97 | loss: 0.43505 |  0:02:02s\n",
            "epoch 98 | loss: 0.4328  |  0:02:04s\n",
            "epoch 99 | loss: 0.43307 |  0:02:05s\n",
            "epoch 100| loss: 0.43295 |  0:02:06s\n",
            "epoch 101| loss: 0.43187 |  0:02:07s\n",
            "epoch 102| loss: 0.43328 |  0:02:09s\n",
            "epoch 103| loss: 0.44168 |  0:02:10s\n",
            "epoch 104| loss: 0.43236 |  0:02:11s\n",
            "epoch 105| loss: 0.43122 |  0:02:12s\n",
            "epoch 106| loss: 0.43386 |  0:02:14s\n",
            "epoch 107| loss: 0.43303 |  0:02:15s\n",
            "epoch 108| loss: 0.43184 |  0:02:16s\n",
            "epoch 109| loss: 0.43308 |  0:02:17s\n",
            "epoch 110| loss: 0.42814 |  0:02:19s\n",
            "epoch 111| loss: 0.42941 |  0:02:20s\n",
            "epoch 112| loss: 0.43123 |  0:02:21s\n",
            "epoch 113| loss: 0.42767 |  0:02:22s\n",
            "epoch 114| loss: 0.42889 |  0:02:24s\n",
            "epoch 115| loss: 0.43403 |  0:02:25s\n",
            "epoch 116| loss: 0.43515 |  0:02:26s\n",
            "epoch 117| loss: 0.43227 |  0:02:27s\n",
            "epoch 118| loss: 0.42893 |  0:02:28s\n",
            "epoch 119| loss: 0.42823 |  0:02:30s\n",
            "epoch 120| loss: 0.42758 |  0:02:31s\n",
            "epoch 121| loss: 0.42802 |  0:02:32s\n",
            "epoch 122| loss: 0.42837 |  0:02:33s\n",
            "epoch 123| loss: 0.43087 |  0:02:35s\n",
            "epoch 124| loss: 0.4288  |  0:02:36s\n",
            "epoch 125| loss: 0.42958 |  0:02:37s\n",
            "epoch 126| loss: 0.42961 |  0:02:38s\n",
            "epoch 127| loss: 0.43625 |  0:02:40s\n",
            "epoch 128| loss: 0.43253 |  0:02:41s\n",
            "epoch 129| loss: 0.43003 |  0:02:42s\n",
            "epoch 130| loss: 0.42834 |  0:02:43s\n",
            "epoch 131| loss: 0.42879 |  0:02:45s\n",
            "epoch 132| loss: 0.43457 |  0:02:46s\n",
            "epoch 133| loss: 0.43431 |  0:02:47s\n",
            "epoch 134| loss: 0.43116 |  0:02:48s\n",
            "epoch 135| loss: 0.42883 |  0:02:50s\n",
            "epoch 136| loss: 0.42755 |  0:02:51s\n",
            "epoch 137| loss: 0.42975 |  0:02:52s\n",
            "epoch 138| loss: 0.43036 |  0:02:53s\n",
            "epoch 139| loss: 0.43162 |  0:02:55s\n",
            "epoch 140| loss: 0.43007 |  0:02:56s\n",
            "epoch 141| loss: 0.43068 |  0:02:57s\n",
            "epoch 142| loss: 0.43009 |  0:02:58s\n",
            "epoch 143| loss: 0.42837 |  0:03:00s\n",
            "epoch 144| loss: 0.42905 |  0:03:01s\n",
            "epoch 145| loss: 0.42841 |  0:03:02s\n",
            "epoch 146| loss: 0.43002 |  0:03:03s\n",
            "epoch 147| loss: 0.43    |  0:03:05s\n",
            "epoch 148| loss: 0.43958 |  0:03:06s\n",
            "epoch 149| loss: 0.43226 |  0:03:07s\n",
            "epoch 150| loss: 0.43415 |  0:03:08s\n",
            "epoch 151| loss: 0.43002 |  0:03:10s\n",
            "epoch 152| loss: 0.42838 |  0:03:11s\n",
            "epoch 153| loss: 0.42857 |  0:03:12s\n",
            "epoch 154| loss: 0.42902 |  0:03:13s\n",
            "epoch 155| loss: 0.42832 |  0:03:15s\n",
            "epoch 156| loss: 0.42881 |  0:03:16s\n",
            "epoch 157| loss: 0.42837 |  0:03:17s\n",
            "epoch 158| loss: 0.42943 |  0:03:18s\n",
            "epoch 159| loss: 0.42849 |  0:03:20s\n",
            "epoch 160| loss: 0.4284  |  0:03:21s\n",
            "epoch 161| loss: 0.43218 |  0:03:22s\n",
            "epoch 162| loss: 0.4305  |  0:03:23s\n",
            "epoch 163| loss: 0.43274 |  0:03:25s\n",
            "epoch 164| loss: 0.42936 |  0:03:26s\n",
            "epoch 165| loss: 0.42973 |  0:03:27s\n",
            "epoch 166| loss: 0.43204 |  0:03:28s\n",
            "epoch 167| loss: 0.42906 |  0:03:30s\n",
            "epoch 168| loss: 0.42893 |  0:03:31s\n",
            "epoch 169| loss: 0.42797 |  0:03:32s\n",
            "epoch 170| loss: 0.42717 |  0:03:33s\n",
            "epoch 171| loss: 0.43059 |  0:03:35s\n",
            "epoch 172| loss: 0.42954 |  0:03:36s\n",
            "epoch 173| loss: 0.42681 |  0:03:37s\n",
            "epoch 174| loss: 0.42609 |  0:03:38s\n",
            "epoch 175| loss: 0.42595 |  0:03:40s\n",
            "epoch 176| loss: 0.42616 |  0:03:41s\n",
            "epoch 177| loss: 0.42777 |  0:03:42s\n",
            "epoch 178| loss: 0.42722 |  0:03:43s\n",
            "epoch 179| loss: 0.43121 |  0:03:45s\n",
            "epoch 180| loss: 0.42967 |  0:03:46s\n",
            "epoch 181| loss: 0.42889 |  0:03:47s\n",
            "epoch 182| loss: 0.42972 |  0:03:48s\n",
            "epoch 183| loss: 0.42846 |  0:03:50s\n",
            "epoch 184| loss: 0.42787 |  0:03:51s\n",
            "epoch 185| loss: 0.42653 |  0:03:52s\n",
            "epoch 186| loss: 0.42599 |  0:03:53s\n",
            "epoch 187| loss: 0.4274  |  0:03:55s\n",
            "epoch 188| loss: 0.42811 |  0:03:56s\n",
            "epoch 189| loss: 0.42672 |  0:03:57s\n",
            "epoch 190| loss: 0.42919 |  0:03:58s\n",
            "epoch 191| loss: 0.4386  |  0:04:00s\n",
            "epoch 192| loss: 0.43189 |  0:04:01s\n",
            "epoch 193| loss: 0.42845 |  0:04:02s\n",
            "epoch 194| loss: 0.42947 |  0:04:03s\n",
            "epoch 195| loss: 0.42988 |  0:04:05s\n",
            "epoch 196| loss: 0.42974 |  0:04:06s\n",
            "epoch 197| loss: 0.43044 |  0:04:07s\n",
            "epoch 198| loss: 0.43153 |  0:04:08s\n",
            "epoch 199| loss: 0.42948 |  0:04:10s\n",
            "epoch 200| loss: 0.42907 |  0:04:11s\n",
            "epoch 201| loss: 0.42751 |  0:04:12s\n",
            "epoch 202| loss: 0.42722 |  0:04:13s\n",
            "epoch 203| loss: 0.43094 |  0:04:15s\n",
            "epoch 204| loss: 0.42732 |  0:04:16s\n",
            "epoch 205| loss: 0.42792 |  0:04:17s\n",
            "epoch 206| loss: 0.435   |  0:04:18s\n",
            "epoch 207| loss: 0.43039 |  0:04:20s\n",
            "epoch 208| loss: 0.42897 |  0:04:21s\n",
            "epoch 209| loss: 0.42646 |  0:04:22s\n",
            "epoch 210| loss: 0.42734 |  0:04:23s\n",
            "epoch 211| loss: 0.42711 |  0:04:25s\n",
            "epoch 212| loss: 0.42731 |  0:04:26s\n",
            "epoch 213| loss: 0.42569 |  0:04:27s\n",
            "epoch 214| loss: 0.42575 |  0:04:28s\n",
            "epoch 215| loss: 0.4295  |  0:04:30s\n",
            "epoch 216| loss: 0.43603 |  0:04:31s\n",
            "epoch 217| loss: 0.43111 |  0:04:32s\n",
            "epoch 218| loss: 0.42818 |  0:04:33s\n",
            "epoch 219| loss: 0.43354 |  0:04:35s\n",
            "epoch 220| loss: 0.42874 |  0:04:36s\n",
            "epoch 221| loss: 0.42617 |  0:04:37s\n",
            "epoch 222| loss: 0.42572 |  0:04:38s\n",
            "epoch 223| loss: 0.42588 |  0:04:40s\n",
            "epoch 224| loss: 0.42576 |  0:04:41s\n",
            "epoch 225| loss: 0.42477 |  0:04:42s\n",
            "epoch 226| loss: 0.42545 |  0:04:43s\n",
            "epoch 227| loss: 0.42697 |  0:04:45s\n",
            "epoch 228| loss: 0.42713 |  0:04:46s\n",
            "epoch 229| loss: 0.42902 |  0:04:47s\n",
            "epoch 230| loss: 0.43041 |  0:04:48s\n",
            "epoch 231| loss: 0.43815 |  0:04:50s\n",
            "epoch 232| loss: 0.4302  |  0:04:51s\n",
            "epoch 233| loss: 0.42825 |  0:04:52s\n",
            "epoch 234| loss: 0.42801 |  0:04:53s\n",
            "epoch 235| loss: 0.42736 |  0:04:54s\n",
            "epoch 236| loss: 0.42472 |  0:04:56s\n",
            "epoch 237| loss: 0.42528 |  0:04:57s\n",
            "epoch 238| loss: 0.42531 |  0:04:58s\n",
            "epoch 239| loss: 0.42522 |  0:04:59s\n",
            "epoch 240| loss: 0.42446 |  0:05:01s\n",
            "epoch 241| loss: 0.42392 |  0:05:02s\n",
            "epoch 242| loss: 0.42377 |  0:05:03s\n",
            "epoch 243| loss: 0.42421 |  0:05:04s\n",
            "epoch 244| loss: 0.42525 |  0:05:06s\n",
            "epoch 245| loss: 0.42566 |  0:05:07s\n",
            "epoch 246| loss: 0.42656 |  0:05:08s\n",
            "epoch 247| loss: 0.42686 |  0:05:09s\n",
            "epoch 248| loss: 0.42607 |  0:05:11s\n",
            "epoch 249| loss: 0.42388 |  0:05:12s\n",
            "epoch 250| loss: 0.42306 |  0:05:13s\n",
            "epoch 251| loss: 0.42612 |  0:05:14s\n",
            "epoch 252| loss: 0.42475 |  0:05:16s\n",
            "epoch 253| loss: 0.42505 |  0:05:17s\n",
            "epoch 254| loss: 0.424   |  0:05:18s\n",
            "epoch 255| loss: 0.42591 |  0:05:19s\n",
            "epoch 256| loss: 0.4247  |  0:05:21s\n",
            "epoch 257| loss: 0.42397 |  0:05:22s\n",
            "epoch 258| loss: 0.42347 |  0:05:23s\n",
            "epoch 259| loss: 0.42402 |  0:05:24s\n",
            "epoch 260| loss: 0.42741 |  0:05:26s\n",
            "epoch 261| loss: 0.42869 |  0:05:27s\n",
            "epoch 262| loss: 0.4253  |  0:05:28s\n",
            "epoch 263| loss: 0.42269 |  0:05:29s\n",
            "epoch 264| loss: 0.42339 |  0:05:31s\n",
            "epoch 265| loss: 0.42453 |  0:05:32s\n",
            "epoch 266| loss: 0.42553 |  0:05:33s\n",
            "epoch 267| loss: 0.42369 |  0:05:34s\n",
            "epoch 268| loss: 0.42476 |  0:05:36s\n",
            "epoch 269| loss: 0.42293 |  0:05:37s\n",
            "epoch 270| loss: 0.42499 |  0:05:38s\n",
            "epoch 271| loss: 0.42252 |  0:05:39s\n",
            "epoch 272| loss: 0.42406 |  0:05:41s\n",
            "epoch 273| loss: 0.42513 |  0:05:42s\n",
            "epoch 274| loss: 0.42531 |  0:05:43s\n",
            "epoch 275| loss: 0.42488 |  0:05:45s\n",
            "epoch 276| loss: 0.43087 |  0:05:46s\n",
            "epoch 277| loss: 0.42613 |  0:05:47s\n",
            "epoch 278| loss: 0.4245  |  0:05:48s\n",
            "epoch 279| loss: 0.42444 |  0:05:50s\n",
            "epoch 280| loss: 0.43101 |  0:05:51s\n",
            "epoch 281| loss: 0.42623 |  0:05:52s\n",
            "epoch 282| loss: 0.42678 |  0:05:53s\n",
            "epoch 283| loss: 0.42478 |  0:05:55s\n",
            "epoch 284| loss: 0.42378 |  0:05:56s\n",
            "epoch 285| loss: 0.42427 |  0:05:57s\n",
            "epoch 286| loss: 0.42296 |  0:05:59s\n",
            "epoch 287| loss: 0.4244  |  0:06:00s\n",
            "epoch 288| loss: 0.42216 |  0:06:01s\n",
            "epoch 289| loss: 0.42512 |  0:06:02s\n",
            "epoch 290| loss: 0.42274 |  0:06:04s\n",
            "epoch 291| loss: 0.42195 |  0:06:05s\n",
            "epoch 292| loss: 0.42281 |  0:06:06s\n",
            "epoch 293| loss: 0.42368 |  0:06:07s\n",
            "epoch 294| loss: 0.42305 |  0:06:09s\n",
            "epoch 295| loss: 0.4309  |  0:06:10s\n",
            "epoch 296| loss: 0.42299 |  0:06:11s\n",
            "epoch 297| loss: 0.42239 |  0:06:12s\n",
            "epoch 298| loss: 0.42228 |  0:06:14s\n",
            "epoch 299| loss: 0.42243 |  0:06:15s\n",
            "epoch 300| loss: 0.42312 |  0:06:16s\n",
            "epoch 301| loss: 0.42517 |  0:06:17s\n",
            "epoch 302| loss: 0.4287  |  0:06:19s\n",
            "epoch 303| loss: 0.42284 |  0:06:20s\n",
            "epoch 304| loss: 0.44142 |  0:06:21s\n",
            "epoch 305| loss: 0.42549 |  0:06:22s\n",
            "epoch 306| loss: 0.42281 |  0:06:24s\n",
            "epoch 307| loss: 0.42094 |  0:06:25s\n",
            "epoch 308| loss: 0.42204 |  0:06:26s\n",
            "epoch 309| loss: 0.42048 |  0:06:27s\n",
            "epoch 310| loss: 0.42119 |  0:06:29s\n",
            "epoch 311| loss: 0.42215 |  0:06:30s\n",
            "epoch 312| loss: 0.42265 |  0:06:31s\n",
            "epoch 313| loss: 0.42151 |  0:06:32s\n",
            "epoch 314| loss: 0.4216  |  0:06:34s\n",
            "epoch 315| loss: 0.42073 |  0:06:35s\n",
            "epoch 316| loss: 0.41951 |  0:06:36s\n",
            "epoch 317| loss: 0.42096 |  0:06:38s\n",
            "epoch 318| loss: 0.42526 |  0:06:39s\n",
            "epoch 319| loss: 0.42323 |  0:06:40s\n",
            "epoch 320| loss: 0.42038 |  0:06:41s\n",
            "epoch 321| loss: 0.42142 |  0:06:43s\n",
            "epoch 322| loss: 0.41972 |  0:06:44s\n",
            "epoch 323| loss: 0.4214  |  0:06:45s\n",
            "epoch 324| loss: 0.42285 |  0:06:46s\n",
            "epoch 325| loss: 0.42058 |  0:06:48s\n",
            "epoch 326| loss: 0.41829 |  0:06:49s\n",
            "epoch 327| loss: 0.42776 |  0:06:50s\n",
            "epoch 328| loss: 0.41965 |  0:06:51s\n",
            "epoch 329| loss: 0.42046 |  0:06:53s\n",
            "epoch 330| loss: 0.42    |  0:06:54s\n",
            "epoch 331| loss: 0.42071 |  0:06:55s\n",
            "epoch 332| loss: 0.42042 |  0:06:56s\n",
            "epoch 333| loss: 0.42123 |  0:06:58s\n",
            "epoch 334| loss: 0.42073 |  0:06:59s\n",
            "epoch 335| loss: 0.42058 |  0:07:00s\n",
            "epoch 336| loss: 0.4193  |  0:07:02s\n",
            "epoch 337| loss: 0.41946 |  0:07:03s\n",
            "epoch 338| loss: 0.42022 |  0:07:04s\n",
            "epoch 339| loss: 0.42348 |  0:07:05s\n",
            "epoch 340| loss: 0.42005 |  0:07:07s\n",
            "epoch 341| loss: 0.41853 |  0:07:08s\n",
            "epoch 342| loss: 0.42095 |  0:07:09s\n",
            "epoch 343| loss: 0.4193  |  0:07:10s\n",
            "epoch 344| loss: 0.41851 |  0:07:12s\n",
            "epoch 345| loss: 0.42347 |  0:07:13s\n",
            "epoch 346| loss: 0.41877 |  0:07:14s\n",
            "epoch 347| loss: 0.41866 |  0:07:15s\n",
            "epoch 348| loss: 0.42022 |  0:07:17s\n",
            "epoch 349| loss: 0.41977 |  0:07:18s\n",
            "epoch 350| loss: 0.41971 |  0:07:19s\n",
            "epoch 351| loss: 0.41785 |  0:07:20s\n",
            "epoch 352| loss: 0.41816 |  0:07:22s\n",
            "epoch 353| loss: 0.41865 |  0:07:23s\n",
            "epoch 354| loss: 0.42082 |  0:07:24s\n",
            "epoch 355| loss: 0.41901 |  0:07:25s\n",
            "epoch 356| loss: 0.4166  |  0:07:26s\n",
            "epoch 357| loss: 0.41802 |  0:07:28s\n",
            "epoch 358| loss: 0.41768 |  0:07:29s\n",
            "epoch 359| loss: 0.41647 |  0:07:30s\n",
            "epoch 360| loss: 0.41689 |  0:07:31s\n",
            "epoch 361| loss: 0.41764 |  0:07:33s\n",
            "epoch 362| loss: 0.41679 |  0:07:34s\n",
            "epoch 363| loss: 0.41921 |  0:07:35s\n",
            "epoch 364| loss: 0.4176  |  0:07:36s\n",
            "epoch 365| loss: 0.41811 |  0:07:38s\n",
            "epoch 366| loss: 0.41923 |  0:07:39s\n",
            "epoch 367| loss: 0.43354 |  0:07:40s\n",
            "epoch 368| loss: 0.42246 |  0:07:41s\n",
            "epoch 369| loss: 0.42038 |  0:07:43s\n",
            "epoch 370| loss: 0.4212  |  0:07:44s\n",
            "epoch 371| loss: 0.41766 |  0:07:45s\n",
            "epoch 372| loss: 0.41583 |  0:07:46s\n",
            "epoch 373| loss: 0.41539 |  0:07:47s\n",
            "epoch 374| loss: 0.41694 |  0:07:49s\n",
            "epoch 375| loss: 0.41569 |  0:07:50s\n",
            "epoch 376| loss: 0.41743 |  0:07:51s\n",
            "epoch 377| loss: 0.41595 |  0:07:52s\n",
            "epoch 378| loss: 0.41632 |  0:07:54s\n",
            "epoch 379| loss: 0.41498 |  0:07:55s\n",
            "epoch 380| loss: 0.41389 |  0:07:56s\n",
            "epoch 381| loss: 0.41486 |  0:07:57s\n",
            "epoch 382| loss: 0.41448 |  0:07:58s\n",
            "epoch 383| loss: 0.41809 |  0:08:00s\n",
            "epoch 384| loss: 0.41794 |  0:08:01s\n",
            "epoch 385| loss: 0.419   |  0:08:02s\n",
            "epoch 386| loss: 0.41636 |  0:08:03s\n",
            "epoch 387| loss: 0.41336 |  0:08:05s\n",
            "epoch 388| loss: 0.4154  |  0:08:06s\n",
            "epoch 389| loss: 0.41604 |  0:08:07s\n",
            "epoch 390| loss: 0.41494 |  0:08:08s\n",
            "epoch 391| loss: 0.41381 |  0:08:10s\n",
            "epoch 392| loss: 0.4157  |  0:08:11s\n",
            "epoch 393| loss: 0.41424 |  0:08:12s\n",
            "epoch 394| loss: 0.41348 |  0:08:13s\n",
            "epoch 395| loss: 0.41318 |  0:08:14s\n",
            "epoch 396| loss: 0.41221 |  0:08:16s\n",
            "epoch 397| loss: 0.41377 |  0:08:17s\n",
            "epoch 398| loss: 0.4162  |  0:08:18s\n",
            "epoch 399| loss: 0.41485 |  0:08:19s\n",
            "epoch 400| loss: 0.41295 |  0:08:21s\n",
            "epoch 401| loss: 0.41456 |  0:08:22s\n",
            "epoch 402| loss: 0.41281 |  0:08:23s\n",
            "epoch 403| loss: 0.41258 |  0:08:24s\n",
            "epoch 404| loss: 0.41273 |  0:08:25s\n",
            "epoch 405| loss: 0.41342 |  0:08:27s\n",
            "epoch 406| loss: 0.4145  |  0:08:28s\n",
            "epoch 407| loss: 0.41456 |  0:08:29s\n",
            "epoch 408| loss: 0.41305 |  0:08:30s\n",
            "epoch 409| loss: 0.41216 |  0:08:31s\n",
            "epoch 410| loss: 0.41747 |  0:08:33s\n",
            "epoch 411| loss: 0.41375 |  0:08:34s\n",
            "epoch 412| loss: 0.41361 |  0:08:35s\n",
            "epoch 413| loss: 0.41305 |  0:08:36s\n",
            "epoch 414| loss: 0.41176 |  0:08:38s\n",
            "epoch 415| loss: 0.41214 |  0:08:39s\n",
            "epoch 416| loss: 0.41137 |  0:08:40s\n",
            "epoch 417| loss: 0.41234 |  0:08:41s\n",
            "epoch 418| loss: 0.41323 |  0:08:43s\n",
            "epoch 419| loss: 0.41564 |  0:08:44s\n",
            "epoch 420| loss: 0.41484 |  0:08:45s\n",
            "epoch 421| loss: 0.41238 |  0:08:46s\n",
            "epoch 422| loss: 0.41245 |  0:08:48s\n",
            "epoch 423| loss: 0.41292 |  0:08:49s\n",
            "epoch 424| loss: 0.41138 |  0:08:50s\n",
            "epoch 425| loss: 0.41064 |  0:08:51s\n",
            "epoch 426| loss: 0.41318 |  0:08:53s\n",
            "epoch 427| loss: 0.41469 |  0:08:54s\n",
            "epoch 428| loss: 0.41234 |  0:08:55s\n",
            "epoch 429| loss: 0.41138 |  0:08:57s\n",
            "epoch 430| loss: 0.41338 |  0:08:58s\n",
            "epoch 431| loss: 0.41221 |  0:08:59s\n",
            "epoch 432| loss: 0.41037 |  0:09:00s\n",
            "epoch 433| loss: 0.41177 |  0:09:02s\n",
            "epoch 434| loss: 0.41292 |  0:09:03s\n",
            "epoch 435| loss: 0.41359 |  0:09:04s\n",
            "epoch 436| loss: 0.41119 |  0:09:05s\n",
            "epoch 437| loss: 0.41183 |  0:09:07s\n",
            "epoch 438| loss: 0.41097 |  0:09:08s\n",
            "epoch 439| loss: 0.41057 |  0:09:09s\n",
            "epoch 440| loss: 0.41057 |  0:09:10s\n",
            "epoch 441| loss: 0.40913 |  0:09:12s\n",
            "epoch 442| loss: 0.41025 |  0:09:13s\n",
            "epoch 443| loss: 0.41453 |  0:09:14s\n",
            "epoch 444| loss: 0.40868 |  0:09:15s\n",
            "epoch 445| loss: 0.41161 |  0:09:17s\n",
            "epoch 446| loss: 0.41117 |  0:09:18s\n",
            "epoch 447| loss: 0.41166 |  0:09:19s\n",
            "epoch 448| loss: 0.40986 |  0:09:20s\n",
            "epoch 449| loss: 0.40902 |  0:09:22s\n",
            "epoch 450| loss: 0.41137 |  0:09:23s\n",
            "epoch 451| loss: 0.41135 |  0:09:24s\n",
            "epoch 452| loss: 0.40995 |  0:09:25s\n",
            "epoch 453| loss: 0.40945 |  0:09:27s\n",
            "epoch 454| loss: 0.40981 |  0:09:28s\n",
            "epoch 455| loss: 0.4094  |  0:09:29s\n",
            "epoch 456| loss: 0.40735 |  0:09:30s\n",
            "epoch 457| loss: 0.4092  |  0:09:32s\n",
            "epoch 458| loss: 0.41128 |  0:09:33s\n",
            "epoch 459| loss: 0.4166  |  0:09:34s\n",
            "epoch 460| loss: 0.41062 |  0:09:35s\n",
            "epoch 461| loss: 0.41218 |  0:09:37s\n",
            "epoch 462| loss: 0.40985 |  0:09:38s\n",
            "epoch 463| loss: 0.409   |  0:09:39s\n",
            "epoch 464| loss: 0.41064 |  0:09:40s\n",
            "epoch 465| loss: 0.40836 |  0:09:42s\n",
            "epoch 466| loss: 0.40876 |  0:09:43s\n",
            "epoch 467| loss: 0.40781 |  0:09:44s\n",
            "epoch 468| loss: 0.40803 |  0:09:45s\n",
            "epoch 469| loss: 0.40603 |  0:09:47s\n",
            "epoch 470| loss: 0.40737 |  0:09:48s\n",
            "epoch 471| loss: 0.40893 |  0:09:49s\n",
            "epoch 472| loss: 0.40924 |  0:09:50s\n",
            "epoch 473| loss: 0.40919 |  0:09:52s\n",
            "epoch 474| loss: 0.40564 |  0:09:53s\n",
            "epoch 475| loss: 0.40731 |  0:09:54s\n",
            "epoch 476| loss: 0.40797 |  0:09:55s\n",
            "epoch 477| loss: 0.40604 |  0:09:57s\n",
            "epoch 478| loss: 0.40662 |  0:09:58s\n",
            "epoch 479| loss: 0.40917 |  0:09:59s\n",
            "epoch 480| loss: 0.41009 |  0:10:00s\n",
            "epoch 481| loss: 0.40791 |  0:10:02s\n",
            "epoch 482| loss: 0.4137  |  0:10:03s\n",
            "epoch 483| loss: 0.40693 |  0:10:04s\n",
            "epoch 484| loss: 0.40642 |  0:10:05s\n",
            "epoch 485| loss: 0.4087  |  0:10:07s\n",
            "epoch 486| loss: 0.41221 |  0:10:08s\n",
            "epoch 487| loss: 0.40807 |  0:10:09s\n",
            "epoch 488| loss: 0.40689 |  0:10:10s\n",
            "epoch 489| loss: 0.40416 |  0:10:12s\n",
            "epoch 490| loss: 0.40561 |  0:10:13s\n",
            "epoch 491| loss: 0.40732 |  0:10:14s\n",
            "epoch 492| loss: 0.40673 |  0:10:15s\n",
            "epoch 493| loss: 0.40833 |  0:10:16s\n",
            "epoch 494| loss: 0.40892 |  0:10:18s\n",
            "epoch 495| loss: 0.40457 |  0:10:19s\n",
            "epoch 496| loss: 0.40687 |  0:10:20s\n",
            "epoch 497| loss: 0.40694 |  0:10:21s\n",
            "epoch 498| loss: 0.4054  |  0:10:23s\n",
            "epoch 499| loss: 0.40531 |  0:10:24s\n",
            "epoch 500| loss: 0.40512 |  0:10:25s\n",
            "epoch 501| loss: 0.40485 |  0:10:26s\n",
            "epoch 502| loss: 0.40432 |  0:10:28s\n",
            "epoch 503| loss: 0.4053  |  0:10:29s\n",
            "epoch 504| loss: 0.40585 |  0:10:30s\n",
            "epoch 505| loss: 0.4042  |  0:10:31s\n",
            "epoch 506| loss: 0.40269 |  0:10:33s\n",
            "epoch 507| loss: 0.40594 |  0:10:34s\n",
            "epoch 508| loss: 0.40587 |  0:10:35s\n",
            "epoch 509| loss: 0.40711 |  0:10:36s\n",
            "epoch 510| loss: 0.40548 |  0:10:38s\n",
            "epoch 511| loss: 0.40562 |  0:10:39s\n",
            "epoch 512| loss: 0.40447 |  0:10:40s\n",
            "epoch 513| loss: 0.40618 |  0:10:41s\n",
            "epoch 514| loss: 0.4041  |  0:10:42s\n",
            "epoch 515| loss: 0.40522 |  0:10:44s\n",
            "epoch 516| loss: 0.40483 |  0:10:45s\n",
            "epoch 517| loss: 0.40447 |  0:10:46s\n",
            "epoch 518| loss: 0.40668 |  0:10:47s\n",
            "epoch 519| loss: 0.40467 |  0:10:49s\n",
            "epoch 520| loss: 0.40477 |  0:10:50s\n",
            "epoch 521| loss: 0.40324 |  0:10:51s\n",
            "epoch 522| loss: 0.40413 |  0:10:52s\n",
            "epoch 523| loss: 0.40598 |  0:10:54s\n",
            "epoch 524| loss: 0.40579 |  0:10:55s\n",
            "epoch 525| loss: 0.40231 |  0:10:56s\n",
            "epoch 526| loss: 0.4041  |  0:10:57s\n",
            "epoch 527| loss: 0.4058  |  0:10:59s\n",
            "epoch 528| loss: 0.40511 |  0:11:00s\n",
            "epoch 529| loss: 0.4125  |  0:11:01s\n",
            "epoch 530| loss: 0.40676 |  0:11:03s\n",
            "epoch 531| loss: 0.40348 |  0:11:04s\n",
            "epoch 532| loss: 0.40349 |  0:11:05s\n",
            "epoch 533| loss: 0.40704 |  0:11:06s\n",
            "epoch 534| loss: 0.40214 |  0:11:08s\n",
            "epoch 535| loss: 0.40212 |  0:11:09s\n",
            "epoch 536| loss: 0.40213 |  0:11:10s\n",
            "epoch 537| loss: 0.40143 |  0:11:11s\n",
            "epoch 538| loss: 0.40387 |  0:11:13s\n",
            "epoch 539| loss: 0.39952 |  0:11:14s\n",
            "epoch 540| loss: 0.40368 |  0:11:15s\n",
            "epoch 541| loss: 0.40555 |  0:11:16s\n",
            "epoch 542| loss: 0.40197 |  0:11:18s\n",
            "epoch 543| loss: 0.40106 |  0:11:19s\n",
            "epoch 544| loss: 0.40279 |  0:11:20s\n",
            "epoch 545| loss: 0.40474 |  0:11:21s\n",
            "epoch 546| loss: 0.40123 |  0:11:23s\n",
            "epoch 547| loss: 0.40285 |  0:11:24s\n",
            "epoch 548| loss: 0.40094 |  0:11:25s\n",
            "epoch 549| loss: 0.40719 |  0:11:26s\n",
            "epoch 550| loss: 0.40382 |  0:11:28s\n",
            "epoch 551| loss: 0.40108 |  0:11:29s\n",
            "epoch 552| loss: 0.40246 |  0:11:30s\n",
            "epoch 553| loss: 0.4015  |  0:11:31s\n",
            "epoch 554| loss: 0.40623 |  0:11:33s\n",
            "epoch 555| loss: 0.40251 |  0:11:34s\n",
            "epoch 556| loss: 0.40053 |  0:11:35s\n",
            "epoch 557| loss: 0.40103 |  0:11:36s\n",
            "epoch 558| loss: 0.40282 |  0:11:38s\n",
            "epoch 559| loss: 0.40019 |  0:11:39s\n",
            "epoch 560| loss: 0.40616 |  0:11:40s\n",
            "epoch 561| loss: 0.40357 |  0:11:41s\n",
            "epoch 562| loss: 0.39883 |  0:11:42s\n",
            "epoch 563| loss: 0.3986  |  0:11:44s\n",
            "epoch 564| loss: 0.39834 |  0:11:45s\n",
            "epoch 565| loss: 0.40114 |  0:11:46s\n",
            "epoch 566| loss: 0.40321 |  0:11:48s\n",
            "epoch 567| loss: 0.40329 |  0:11:49s\n",
            "epoch 568| loss: 0.39911 |  0:11:50s\n",
            "epoch 569| loss: 0.40168 |  0:11:51s\n",
            "epoch 570| loss: 0.39881 |  0:11:53s\n",
            "epoch 571| loss: 0.40065 |  0:11:54s\n",
            "epoch 572| loss: 0.40138 |  0:11:55s\n",
            "epoch 573| loss: 0.40005 |  0:11:56s\n",
            "epoch 574| loss: 0.40069 |  0:11:58s\n",
            "epoch 575| loss: 0.39816 |  0:11:59s\n",
            "epoch 576| loss: 0.40099 |  0:12:00s\n",
            "epoch 577| loss: 0.4014  |  0:12:01s\n",
            "epoch 578| loss: 0.40126 |  0:12:03s\n",
            "epoch 579| loss: 0.39985 |  0:12:04s\n",
            "epoch 580| loss: 0.40221 |  0:12:05s\n",
            "epoch 581| loss: 0.3983  |  0:12:06s\n",
            "epoch 582| loss: 0.3999  |  0:12:08s\n",
            "epoch 583| loss: 0.39772 |  0:12:09s\n",
            "epoch 584| loss: 0.39903 |  0:12:10s\n",
            "epoch 585| loss: 0.40022 |  0:12:11s\n",
            "epoch 586| loss: 0.39876 |  0:12:13s\n",
            "epoch 587| loss: 0.39978 |  0:12:14s\n",
            "epoch 588| loss: 0.39595 |  0:12:15s\n",
            "epoch 589| loss: 0.3989  |  0:12:16s\n",
            "epoch 590| loss: 0.39783 |  0:12:18s\n",
            "epoch 591| loss: 0.40201 |  0:12:19s\n",
            "epoch 592| loss: 0.39706 |  0:12:20s\n",
            "epoch 593| loss: 0.40159 |  0:12:21s\n",
            "epoch 594| loss: 0.39971 |  0:12:23s\n",
            "epoch 595| loss: 0.40143 |  0:12:24s\n",
            "epoch 596| loss: 0.40049 |  0:12:25s\n",
            "epoch 597| loss: 0.40028 |  0:12:26s\n",
            "epoch 598| loss: 0.39788 |  0:12:28s\n",
            "epoch 599| loss: 0.39994 |  0:12:29s\n",
            "epoch 600| loss: 0.39603 |  0:12:30s\n",
            "epoch 601| loss: 0.39641 |  0:12:31s\n",
            "epoch 602| loss: 0.39819 |  0:12:33s\n",
            "epoch 603| loss: 0.39665 |  0:12:34s\n",
            "epoch 604| loss: 0.39821 |  0:12:35s\n",
            "epoch 605| loss: 0.39981 |  0:12:36s\n",
            "epoch 606| loss: 0.39519 |  0:12:38s\n",
            "epoch 607| loss: 0.39629 |  0:12:39s\n",
            "epoch 608| loss: 0.39825 |  0:12:40s\n",
            "epoch 609| loss: 0.39703 |  0:12:41s\n",
            "epoch 610| loss: 0.39664 |  0:12:43s\n",
            "epoch 611| loss: 0.39708 |  0:12:44s\n",
            "epoch 612| loss: 0.40128 |  0:12:45s\n",
            "epoch 613| loss: 0.40522 |  0:12:46s\n",
            "epoch 614| loss: 0.40144 |  0:12:48s\n",
            "epoch 615| loss: 0.39979 |  0:12:49s\n",
            "epoch 616| loss: 0.40073 |  0:12:50s\n",
            "epoch 617| loss: 0.39569 |  0:12:51s\n",
            "epoch 618| loss: 0.39769 |  0:12:53s\n",
            "epoch 619| loss: 0.40197 |  0:12:54s\n",
            "epoch 620| loss: 0.39801 |  0:12:55s\n",
            "epoch 621| loss: 0.39329 |  0:12:56s\n",
            "epoch 622| loss: 0.39518 |  0:12:58s\n",
            "epoch 623| loss: 0.39545 |  0:12:59s\n",
            "epoch 624| loss: 0.39603 |  0:13:00s\n",
            "epoch 625| loss: 0.39544 |  0:13:01s\n",
            "epoch 626| loss: 0.39622 |  0:13:02s\n",
            "epoch 627| loss: 0.39833 |  0:13:04s\n",
            "epoch 628| loss: 0.39467 |  0:13:05s\n",
            "epoch 629| loss: 0.39577 |  0:13:06s\n",
            "epoch 630| loss: 0.39496 |  0:13:07s\n",
            "epoch 631| loss: 0.39495 |  0:13:09s\n",
            "epoch 632| loss: 0.39916 |  0:13:10s\n",
            "epoch 633| loss: 0.39478 |  0:13:11s\n",
            "epoch 634| loss: 0.39315 |  0:13:12s\n",
            "epoch 635| loss: 0.39452 |  0:13:14s\n",
            "epoch 636| loss: 0.39659 |  0:13:15s\n",
            "epoch 637| loss: 0.40094 |  0:13:16s\n",
            "epoch 638| loss: 0.39654 |  0:13:17s\n",
            "epoch 639| loss: 0.39712 |  0:13:19s\n",
            "epoch 640| loss: 0.39509 |  0:13:20s\n",
            "epoch 641| loss: 0.39485 |  0:13:21s\n",
            "epoch 642| loss: 0.39594 |  0:13:22s\n",
            "epoch 643| loss: 0.39439 |  0:13:24s\n",
            "epoch 644| loss: 0.39428 |  0:13:25s\n",
            "epoch 645| loss: 0.39534 |  0:13:26s\n",
            "epoch 646| loss: 0.39597 |  0:13:27s\n",
            "epoch 647| loss: 0.39634 |  0:13:29s\n",
            "epoch 648| loss: 0.3929  |  0:13:30s\n",
            "epoch 649| loss: 0.39295 |  0:13:31s\n",
            "epoch 650| loss: 0.39483 |  0:13:32s\n",
            "epoch 651| loss: 0.39509 |  0:13:34s\n",
            "epoch 652| loss: 0.39318 |  0:13:35s\n",
            "epoch 653| loss: 0.39341 |  0:13:36s\n",
            "epoch 654| loss: 0.39607 |  0:13:37s\n",
            "epoch 655| loss: 0.39485 |  0:13:39s\n",
            "epoch 656| loss: 0.39424 |  0:13:40s\n",
            "epoch 657| loss: 0.39159 |  0:13:41s\n",
            "epoch 658| loss: 0.39425 |  0:13:42s\n",
            "epoch 659| loss: 0.39275 |  0:13:44s\n",
            "epoch 660| loss: 0.39272 |  0:13:45s\n",
            "epoch 661| loss: 0.39832 |  0:13:46s\n",
            "epoch 662| loss: 0.39644 |  0:13:48s\n",
            "epoch 663| loss: 0.39385 |  0:13:49s\n",
            "epoch 664| loss: 0.39176 |  0:13:50s\n",
            "epoch 665| loss: 0.39701 |  0:13:52s\n",
            "epoch 666| loss: 0.3968  |  0:13:53s\n",
            "epoch 667| loss: 0.39479 |  0:13:54s\n",
            "epoch 668| loss: 0.39235 |  0:13:56s\n",
            "epoch 669| loss: 0.39346 |  0:13:57s\n",
            "epoch 670| loss: 0.39475 |  0:13:59s\n",
            "epoch 671| loss: 0.39249 |  0:14:00s\n",
            "epoch 672| loss: 0.39122 |  0:14:01s\n",
            "epoch 673| loss: 0.39329 |  0:14:03s\n",
            "epoch 674| loss: 0.39471 |  0:14:04s\n",
            "epoch 675| loss: 0.39444 |  0:14:05s\n",
            "epoch 676| loss: 0.39074 |  0:14:07s\n",
            "epoch 677| loss: 0.39269 |  0:14:08s\n",
            "epoch 678| loss: 0.39092 |  0:14:09s\n",
            "epoch 679| loss: 0.39336 |  0:14:11s\n",
            "epoch 680| loss: 0.39326 |  0:14:12s\n",
            "epoch 681| loss: 0.39116 |  0:14:13s\n",
            "epoch 682| loss: 0.3942  |  0:14:14s\n",
            "epoch 683| loss: 0.39412 |  0:14:16s\n",
            "epoch 684| loss: 0.39055 |  0:14:17s\n",
            "epoch 685| loss: 0.39121 |  0:14:18s\n",
            "epoch 686| loss: 0.39211 |  0:14:19s\n",
            "epoch 687| loss: 0.39095 |  0:14:21s\n",
            "epoch 688| loss: 0.39086 |  0:14:22s\n",
            "epoch 689| loss: 0.39242 |  0:14:23s\n",
            "epoch 690| loss: 0.39155 |  0:14:24s\n",
            "epoch 691| loss: 0.39059 |  0:14:26s\n",
            "epoch 692| loss: 0.3934  |  0:14:27s\n",
            "epoch 693| loss: 0.39057 |  0:14:28s\n",
            "epoch 694| loss: 0.39265 |  0:14:29s\n",
            "epoch 695| loss: 0.38769 |  0:14:31s\n",
            "epoch 696| loss: 0.39035 |  0:14:32s\n",
            "epoch 697| loss: 0.39448 |  0:14:33s\n",
            "epoch 698| loss: 0.39522 |  0:14:34s\n",
            "epoch 699| loss: 0.39573 |  0:14:36s\n",
            "epoch 700| loss: 0.39167 |  0:14:37s\n",
            "epoch 701| loss: 0.38908 |  0:14:38s\n",
            "epoch 702| loss: 0.38941 |  0:14:39s\n",
            "epoch 703| loss: 0.38696 |  0:14:41s\n",
            "epoch 704| loss: 0.38981 |  0:14:42s\n",
            "epoch 705| loss: 0.39237 |  0:14:43s\n",
            "epoch 706| loss: 0.39087 |  0:14:44s\n",
            "epoch 707| loss: 0.39079 |  0:14:46s\n",
            "epoch 708| loss: 0.39813 |  0:14:47s\n",
            "epoch 709| loss: 0.39162 |  0:14:48s\n",
            "epoch 710| loss: 0.39131 |  0:14:49s\n",
            "epoch 711| loss: 0.38986 |  0:14:51s\n",
            "epoch 712| loss: 0.38809 |  0:14:52s\n",
            "epoch 713| loss: 0.39078 |  0:14:53s\n",
            "epoch 714| loss: 0.39335 |  0:14:55s\n",
            "epoch 715| loss: 0.39626 |  0:14:56s\n",
            "epoch 716| loss: 0.39093 |  0:14:57s\n",
            "epoch 717| loss: 0.38863 |  0:14:59s\n",
            "epoch 718| loss: 0.38971 |  0:15:00s\n",
            "epoch 719| loss: 0.38926 |  0:15:02s\n",
            "epoch 720| loss: 0.39197 |  0:15:03s\n",
            "epoch 721| loss: 0.39168 |  0:15:04s\n",
            "epoch 722| loss: 0.39514 |  0:15:06s\n",
            "epoch 723| loss: 0.39812 |  0:15:07s\n",
            "epoch 724| loss: 0.39213 |  0:15:08s\n",
            "epoch 725| loss: 0.3907  |  0:15:10s\n",
            "epoch 726| loss: 0.39127 |  0:15:11s\n",
            "epoch 727| loss: 0.39143 |  0:15:12s\n",
            "epoch 728| loss: 0.38885 |  0:15:13s\n",
            "epoch 729| loss: 0.39192 |  0:15:15s\n",
            "epoch 730| loss: 0.38961 |  0:15:16s\n",
            "epoch 731| loss: 0.38962 |  0:15:17s\n",
            "epoch 732| loss: 0.38786 |  0:15:19s\n",
            "epoch 733| loss: 0.39193 |  0:15:20s\n",
            "epoch 734| loss: 0.39003 |  0:15:21s\n",
            "epoch 735| loss: 0.39048 |  0:15:22s\n",
            "epoch 736| loss: 0.40048 |  0:15:24s\n",
            "epoch 737| loss: 0.39459 |  0:15:25s\n",
            "epoch 738| loss: 0.39361 |  0:15:26s\n",
            "epoch 739| loss: 0.39209 |  0:15:27s\n",
            "epoch 740| loss: 0.38945 |  0:15:29s\n",
            "epoch 741| loss: 0.39009 |  0:15:30s\n",
            "epoch 742| loss: 0.39104 |  0:15:31s\n",
            "epoch 743| loss: 0.39136 |  0:15:32s\n",
            "epoch 744| loss: 0.39041 |  0:15:34s\n",
            "epoch 745| loss: 0.39    |  0:15:35s\n",
            "epoch 746| loss: 0.39031 |  0:15:36s\n",
            "epoch 747| loss: 0.38645 |  0:15:37s\n",
            "epoch 748| loss: 0.3878  |  0:15:39s\n",
            "epoch 749| loss: 0.38985 |  0:15:40s\n",
            "epoch 750| loss: 0.38617 |  0:15:41s\n",
            "epoch 751| loss: 0.38823 |  0:15:42s\n",
            "epoch 752| loss: 0.39    |  0:15:44s\n",
            "epoch 753| loss: 0.39073 |  0:15:45s\n",
            "epoch 754| loss: 0.39031 |  0:15:46s\n",
            "epoch 755| loss: 0.38905 |  0:15:47s\n",
            "epoch 756| loss: 0.38899 |  0:15:49s\n",
            "epoch 757| loss: 0.38666 |  0:15:50s\n",
            "epoch 758| loss: 0.38791 |  0:15:51s\n",
            "epoch 759| loss: 0.38527 |  0:15:53s\n",
            "epoch 760| loss: 0.38639 |  0:15:54s\n",
            "epoch 761| loss: 0.38868 |  0:15:55s\n",
            "epoch 762| loss: 0.3878  |  0:15:57s\n",
            "epoch 763| loss: 0.3866  |  0:15:58s\n",
            "epoch 764| loss: 0.38821 |  0:15:59s\n",
            "epoch 765| loss: 0.39124 |  0:16:01s\n",
            "epoch 766| loss: 0.38879 |  0:16:02s\n",
            "epoch 767| loss: 0.38927 |  0:16:04s\n",
            "epoch 768| loss: 0.38516 |  0:16:05s\n",
            "epoch 769| loss: 0.38671 |  0:16:06s\n",
            "epoch 770| loss: 0.38718 |  0:16:08s\n",
            "epoch 771| loss: 0.38893 |  0:16:09s\n",
            "epoch 772| loss: 0.38704 |  0:16:10s\n",
            "epoch 773| loss: 0.38846 |  0:16:12s\n",
            "epoch 774| loss: 0.38945 |  0:16:13s\n",
            "epoch 775| loss: 0.38771 |  0:16:14s\n",
            "epoch 776| loss: 0.39478 |  0:16:16s\n",
            "epoch 777| loss: 0.38979 |  0:16:17s\n",
            "epoch 778| loss: 0.38742 |  0:16:18s\n",
            "epoch 779| loss: 0.38535 |  0:16:19s\n",
            "epoch 780| loss: 0.38871 |  0:16:21s\n",
            "epoch 781| loss: 0.38633 |  0:16:22s\n",
            "epoch 782| loss: 0.38513 |  0:16:23s\n",
            "epoch 783| loss: 0.38391 |  0:16:24s\n",
            "epoch 784| loss: 0.38338 |  0:16:26s\n",
            "epoch 785| loss: 0.38639 |  0:16:27s\n",
            "epoch 786| loss: 0.3874  |  0:16:28s\n",
            "epoch 787| loss: 0.38786 |  0:16:29s\n",
            "epoch 788| loss: 0.3885  |  0:16:31s\n",
            "epoch 789| loss: 0.38471 |  0:16:32s\n",
            "epoch 790| loss: 0.38462 |  0:16:33s\n",
            "epoch 791| loss: 0.38593 |  0:16:34s\n",
            "epoch 792| loss: 0.38703 |  0:16:36s\n",
            "epoch 793| loss: 0.38967 |  0:16:37s\n",
            "epoch 794| loss: 0.38771 |  0:16:38s\n",
            "epoch 795| loss: 0.3865  |  0:16:39s\n",
            "epoch 796| loss: 0.3877  |  0:16:41s\n",
            "epoch 797| loss: 0.39168 |  0:16:42s\n",
            "epoch 798| loss: 0.38687 |  0:16:43s\n",
            "epoch 799| loss: 0.39539 |  0:16:44s\n",
            "epoch 800| loss: 0.3861  |  0:16:46s\n",
            "epoch 801| loss: 0.38415 |  0:16:47s\n",
            "epoch 802| loss: 0.38269 |  0:16:48s\n",
            "epoch 803| loss: 0.3844  |  0:16:49s\n",
            "epoch 804| loss: 0.3819  |  0:16:51s\n",
            "epoch 805| loss: 0.38266 |  0:16:52s\n",
            "epoch 806| loss: 0.38254 |  0:16:53s\n",
            "epoch 807| loss: 0.38733 |  0:16:55s\n",
            "epoch 808| loss: 0.38406 |  0:16:56s\n",
            "epoch 809| loss: 0.38338 |  0:16:57s\n",
            "epoch 810| loss: 0.38464 |  0:16:59s\n",
            "epoch 811| loss: 0.38505 |  0:17:00s\n",
            "epoch 812| loss: 0.38782 |  0:17:02s\n",
            "epoch 813| loss: 0.38549 |  0:17:03s\n",
            "epoch 814| loss: 0.38523 |  0:17:04s\n",
            "epoch 815| loss: 0.38767 |  0:17:06s\n",
            "epoch 816| loss: 0.38414 |  0:17:07s\n",
            "epoch 817| loss: 0.38395 |  0:17:08s\n",
            "epoch 818| loss: 0.38324 |  0:17:10s\n",
            "epoch 819| loss: 0.38655 |  0:17:11s\n",
            "epoch 820| loss: 0.38645 |  0:17:12s\n",
            "epoch 821| loss: 0.3847  |  0:17:14s\n",
            "epoch 822| loss: 0.38519 |  0:17:15s\n",
            "epoch 823| loss: 0.38648 |  0:17:17s\n",
            "epoch 824| loss: 0.38541 |  0:17:18s\n",
            "epoch 825| loss: 0.38589 |  0:17:19s\n",
            "epoch 826| loss: 0.38488 |  0:17:21s\n",
            "epoch 827| loss: 0.38512 |  0:17:22s\n",
            "epoch 828| loss: 0.38615 |  0:17:23s\n",
            "epoch 829| loss: 0.38601 |  0:17:25s\n",
            "epoch 830| loss: 0.38359 |  0:17:26s\n",
            "epoch 831| loss: 0.38325 |  0:17:27s\n",
            "epoch 832| loss: 0.38692 |  0:17:29s\n",
            "epoch 833| loss: 0.3838  |  0:17:30s\n",
            "epoch 834| loss: 0.38594 |  0:17:31s\n",
            "epoch 835| loss: 0.38624 |  0:17:32s\n",
            "epoch 836| loss: 0.3834  |  0:17:34s\n",
            "epoch 837| loss: 0.38268 |  0:17:35s\n",
            "epoch 838| loss: 0.38391 |  0:17:36s\n",
            "epoch 839| loss: 0.38382 |  0:17:38s\n",
            "epoch 840| loss: 0.38387 |  0:17:39s\n",
            "epoch 841| loss: 0.38106 |  0:17:40s\n",
            "epoch 842| loss: 0.38246 |  0:17:41s\n",
            "epoch 843| loss: 0.38424 |  0:17:42s\n",
            "epoch 844| loss: 0.39084 |  0:17:44s\n",
            "epoch 845| loss: 0.38612 |  0:17:45s\n",
            "epoch 846| loss: 0.3836  |  0:17:46s\n",
            "epoch 847| loss: 0.38377 |  0:17:48s\n",
            "epoch 848| loss: 0.38416 |  0:17:49s\n",
            "epoch 849| loss: 0.38399 |  0:17:50s\n",
            "epoch 850| loss: 0.39045 |  0:17:51s\n",
            "epoch 851| loss: 0.38689 |  0:17:53s\n",
            "epoch 852| loss: 0.38404 |  0:17:54s\n",
            "epoch 853| loss: 0.38256 |  0:17:55s\n",
            "epoch 854| loss: 0.38472 |  0:17:57s\n",
            "epoch 855| loss: 0.38107 |  0:17:58s\n",
            "epoch 856| loss: 0.38225 |  0:17:59s\n",
            "epoch 857| loss: 0.38477 |  0:18:01s\n",
            "epoch 858| loss: 0.38279 |  0:18:02s\n",
            "epoch 859| loss: 0.38062 |  0:18:03s\n",
            "epoch 860| loss: 0.38026 |  0:18:05s\n",
            "epoch 861| loss: 0.3842  |  0:18:06s\n",
            "epoch 862| loss: 0.38445 |  0:18:07s\n",
            "epoch 863| loss: 0.38487 |  0:18:09s\n",
            "epoch 864| loss: 0.38233 |  0:18:10s\n",
            "epoch 865| loss: 0.3813  |  0:18:11s\n",
            "epoch 866| loss: 0.3838  |  0:18:13s\n",
            "epoch 867| loss: 0.38512 |  0:18:14s\n",
            "epoch 868| loss: 0.38441 |  0:18:15s\n",
            "epoch 869| loss: 0.3839  |  0:18:17s\n",
            "epoch 870| loss: 0.38256 |  0:18:18s\n",
            "epoch 871| loss: 0.38241 |  0:18:19s\n",
            "epoch 872| loss: 0.38304 |  0:18:21s\n",
            "epoch 873| loss: 0.38195 |  0:18:22s\n",
            "epoch 874| loss: 0.38208 |  0:18:23s\n",
            "epoch 875| loss: 0.3814  |  0:18:24s\n",
            "epoch 876| loss: 0.38143 |  0:18:26s\n",
            "epoch 877| loss: 0.38342 |  0:18:27s\n",
            "epoch 878| loss: 0.38067 |  0:18:28s\n",
            "epoch 879| loss: 0.38282 |  0:18:30s\n",
            "epoch 880| loss: 0.3896  |  0:18:31s\n",
            "epoch 881| loss: 0.38536 |  0:18:32s\n",
            "epoch 882| loss: 0.3806  |  0:18:33s\n",
            "epoch 883| loss: 0.38099 |  0:18:34s\n",
            "epoch 884| loss: 0.38085 |  0:18:36s\n",
            "epoch 885| loss: 0.38205 |  0:18:37s\n",
            "epoch 886| loss: 0.38377 |  0:18:38s\n",
            "epoch 887| loss: 0.38207 |  0:18:39s\n",
            "epoch 888| loss: 0.37925 |  0:18:40s\n",
            "epoch 889| loss: 0.38411 |  0:18:42s\n",
            "epoch 890| loss: 0.38129 |  0:18:43s\n",
            "epoch 891| loss: 0.38202 |  0:18:44s\n",
            "epoch 892| loss: 0.37937 |  0:18:45s\n",
            "epoch 893| loss: 0.38061 |  0:18:46s\n",
            "epoch 894| loss: 0.38481 |  0:18:48s\n",
            "epoch 895| loss: 0.38875 |  0:18:49s\n",
            "epoch 896| loss: 0.38121 |  0:18:50s\n",
            "epoch 897| loss: 0.38522 |  0:18:52s\n",
            "epoch 898| loss: 0.38089 |  0:18:53s\n",
            "epoch 899| loss: 0.38158 |  0:18:54s\n",
            "epoch 900| loss: 0.38441 |  0:18:55s\n",
            "epoch 901| loss: 0.38317 |  0:18:57s\n",
            "epoch 902| loss: 0.38211 |  0:18:58s\n",
            "epoch 903| loss: 0.38215 |  0:18:59s\n",
            "epoch 904| loss: 0.38096 |  0:19:01s\n",
            "epoch 905| loss: 0.37874 |  0:19:02s\n",
            "epoch 906| loss: 0.38204 |  0:19:03s\n",
            "epoch 907| loss: 0.38054 |  0:19:05s\n",
            "epoch 908| loss: 0.38242 |  0:19:06s\n",
            "epoch 909| loss: 0.38002 |  0:19:07s\n",
            "epoch 910| loss: 0.37954 |  0:19:09s\n",
            "epoch 911| loss: 0.38104 |  0:19:10s\n",
            "epoch 912| loss: 0.3796  |  0:19:11s\n",
            "epoch 913| loss: 0.37847 |  0:19:13s\n",
            "epoch 914| loss: 0.37905 |  0:19:14s\n",
            "epoch 915| loss: 0.37941 |  0:19:15s\n",
            "epoch 916| loss: 0.37956 |  0:19:17s\n",
            "epoch 917| loss: 0.38227 |  0:19:18s\n",
            "epoch 918| loss: 0.38607 |  0:19:19s\n",
            "epoch 919| loss: 0.3862  |  0:19:21s\n",
            "epoch 920| loss: 0.38053 |  0:19:22s\n",
            "epoch 921| loss: 0.38252 |  0:19:23s\n",
            "epoch 922| loss: 0.37907 |  0:19:25s\n",
            "epoch 923| loss: 0.38134 |  0:19:26s\n",
            "epoch 924| loss: 0.38032 |  0:19:27s\n",
            "epoch 925| loss: 0.38062 |  0:19:29s\n",
            "epoch 926| loss: 0.38018 |  0:19:30s\n",
            "epoch 927| loss: 0.381   |  0:19:31s\n",
            "epoch 928| loss: 0.38208 |  0:19:32s\n",
            "epoch 929| loss: 0.38265 |  0:19:34s\n",
            "epoch 930| loss: 0.3791  |  0:19:35s\n",
            "epoch 931| loss: 0.38038 |  0:19:36s\n",
            "epoch 932| loss: 0.38059 |  0:19:38s\n",
            "epoch 933| loss: 0.38153 |  0:19:39s\n",
            "epoch 934| loss: 0.38268 |  0:19:40s\n",
            "epoch 935| loss: 0.37839 |  0:19:41s\n",
            "epoch 936| loss: 0.37731 |  0:19:43s\n",
            "epoch 937| loss: 0.37987 |  0:19:44s\n",
            "epoch 938| loss: 0.38031 |  0:19:45s\n",
            "epoch 939| loss: 0.37661 |  0:19:47s\n",
            "epoch 940| loss: 0.37735 |  0:19:48s\n",
            "epoch 941| loss: 0.38168 |  0:19:50s\n",
            "epoch 942| loss: 0.3814  |  0:19:51s\n",
            "epoch 943| loss: 0.37986 |  0:19:52s\n",
            "epoch 944| loss: 0.38419 |  0:19:54s\n",
            "epoch 945| loss: 0.37865 |  0:19:55s\n",
            "epoch 946| loss: 0.38168 |  0:19:56s\n",
            "epoch 947| loss: 0.38173 |  0:19:58s\n",
            "epoch 948| loss: 0.39174 |  0:19:59s\n",
            "epoch 949| loss: 0.38388 |  0:20:00s\n",
            "epoch 950| loss: 0.37951 |  0:20:02s\n",
            "epoch 951| loss: 0.3796  |  0:20:03s\n",
            "epoch 952| loss: 0.37976 |  0:20:04s\n",
            "epoch 953| loss: 0.3793  |  0:20:06s\n",
            "epoch 954| loss: 0.37852 |  0:20:07s\n",
            "epoch 955| loss: 0.3807  |  0:20:08s\n",
            "epoch 956| loss: 0.38043 |  0:20:10s\n",
            "epoch 957| loss: 0.37891 |  0:20:11s\n",
            "epoch 958| loss: 0.3795  |  0:20:12s\n",
            "epoch 959| loss: 0.39519 |  0:20:14s\n",
            "epoch 960| loss: 0.38207 |  0:20:15s\n",
            "epoch 961| loss: 0.38396 |  0:20:16s\n",
            "epoch 962| loss: 0.38085 |  0:20:18s\n",
            "epoch 963| loss: 0.38271 |  0:20:19s\n",
            "epoch 964| loss: 0.37997 |  0:20:20s\n",
            "epoch 965| loss: 0.38302 |  0:20:22s\n",
            "epoch 966| loss: 0.37831 |  0:20:23s\n",
            "epoch 967| loss: 0.37648 |  0:20:24s\n",
            "epoch 968| loss: 0.38014 |  0:20:26s\n",
            "epoch 969| loss: 0.37718 |  0:20:27s\n",
            "epoch 970| loss: 0.38059 |  0:20:28s\n",
            "epoch 971| loss: 0.37704 |  0:20:29s\n",
            "epoch 972| loss: 0.38025 |  0:20:31s\n",
            "epoch 973| loss: 0.37731 |  0:20:32s\n",
            "epoch 974| loss: 0.3779  |  0:20:33s\n",
            "epoch 975| loss: 0.37672 |  0:20:34s\n",
            "epoch 976| loss: 0.37851 |  0:20:35s\n",
            "epoch 977| loss: 0.38094 |  0:20:37s\n",
            "epoch 978| loss: 0.37626 |  0:20:38s\n",
            "epoch 979| loss: 0.37876 |  0:20:39s\n",
            "epoch 980| loss: 0.37878 |  0:20:41s\n",
            "epoch 981| loss: 0.3781  |  0:20:42s\n",
            "epoch 982| loss: 0.37751 |  0:20:44s\n",
            "epoch 983| loss: 0.37837 |  0:20:45s\n",
            "epoch 984| loss: 0.37817 |  0:20:46s\n",
            "epoch 985| loss: 0.37563 |  0:20:48s\n",
            "epoch 986| loss: 0.37803 |  0:20:49s\n",
            "epoch 987| loss: 0.38064 |  0:20:50s\n",
            "epoch 988| loss: 0.3776  |  0:20:52s\n",
            "epoch 989| loss: 0.37752 |  0:20:53s\n",
            "epoch 990| loss: 0.37748 |  0:20:54s\n",
            "epoch 991| loss: 0.37767 |  0:20:56s\n",
            "epoch 992| loss: 0.37806 |  0:20:57s\n",
            "epoch 993| loss: 0.37986 |  0:20:58s\n",
            "epoch 994| loss: 0.37787 |  0:21:00s\n",
            "epoch 995| loss: 0.37897 |  0:21:01s\n",
            "epoch 996| loss: 0.37704 |  0:21:02s\n",
            "epoch 997| loss: 0.37724 |  0:21:04s\n",
            "epoch 998| loss: 0.37758 |  0:21:05s\n",
            "epoch 999| loss: 0.37678 |  0:21:06s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goSvSXBsy34l"
      },
      "source": [
        "preds_valid = clf.predict_proba(X_valid) "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvYSlwgTy7Ov"
      },
      "source": [
        "preds = clf.predict_proba(X_test)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGdX9dfy9Hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f32548-6c62-4aea-a606-0c98693a7bff"
      },
      "source": [
        "clf.feature_importances_"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1195931 , 0.00524409, 0.        , 0.        , 0.00901577,\n",
              "       0.30460626, 0.22244109, 0.05156417, 0.        , 0.01572321,\n",
              "       0.00376633, 0.00475578, 0.0548896 , 0.06220899, 0.        ,\n",
              "       0.        , 0.04897032, 0.0972213 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq9aN7Vm4q1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b641e9-3a47-4b4a-b93d-0c95a28f69c9"
      },
      "source": [
        "i, j, k = [], [], []\n",
        "for row in range(10000):\n",
        "  i.append(preds[0][row][0])\n",
        "  j.append(preds[0][row][1])\n",
        "  k.append(preds[0][row][2])\n",
        "\n",
        "len(i), len(j), len(k)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WDqWF2m5fmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "5adaaa8b-0384-490e-844d-e8204e217acb"
      },
      "source": [
        "submission['0'] = i\n",
        "submission['1'] = j\n",
        "submission['2'] = k\n",
        "submission.head(10)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0.066923</td>\n",
              "      <td>0.105767</td>\n",
              "      <td>8.273093e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.998183</td>\n",
              "      <td>6.506126e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0.042324</td>\n",
              "      <td>0.685748</td>\n",
              "      <td>2.719281e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0.117702</td>\n",
              "      <td>0.352815</td>\n",
              "      <td>5.294828e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.999864</td>\n",
              "      <td>1.967510e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26462</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.999882</td>\n",
              "      <td>3.608802e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26463</td>\n",
              "      <td>0.393776</td>\n",
              "      <td>0.594828</td>\n",
              "      <td>1.139584e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26464</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>0.799113</td>\n",
              "      <td>1.888388e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>26465</td>\n",
              "      <td>0.001397</td>\n",
              "      <td>0.998406</td>\n",
              "      <td>1.972991e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26466</td>\n",
              "      <td>0.039021</td>\n",
              "      <td>0.893072</td>\n",
              "      <td>6.790664e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index         0         1             2\n",
              "0  26457  0.066923  0.105767  8.273093e-01\n",
              "1  26458  0.001817  0.998183  6.506126e-08\n",
              "2  26459  0.042324  0.685748  2.719281e-01\n",
              "3  26460  0.117702  0.352815  5.294828e-01\n",
              "4  26461  0.000117  0.999864  1.967510e-05\n",
              "5  26462  0.000114  0.999882  3.608802e-06\n",
              "6  26463  0.393776  0.594828  1.139584e-02\n",
              "7  26464  0.012048  0.799113  1.888388e-01\n",
              "8  26465  0.001397  0.998406  1.972991e-04\n",
              "9  26466  0.039021  0.893072  6.790664e-02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBWgJhY55psa"
      },
      "source": [
        "submission.to_csv(path+\"submisison_tabnet.csv\",index=False)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R5_on9fEDO3"
      },
      "source": [
        "prediction = pd.read_csv(path+'submisison_tabnet.csv')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo3KO2cgEI6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "57dc4ecf-313b-4993-98c4-7ee9885c0e57"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0.066923</td>\n",
              "      <td>0.105767</td>\n",
              "      <td>8.273093e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.998183</td>\n",
              "      <td>6.506126e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0.042324</td>\n",
              "      <td>0.685748</td>\n",
              "      <td>2.719281e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0.117702</td>\n",
              "      <td>0.352815</td>\n",
              "      <td>5.294828e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.999864</td>\n",
              "      <td>1.967510e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>36452</td>\n",
              "      <td>0.032561</td>\n",
              "      <td>0.967439</td>\n",
              "      <td>7.561642e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>36453</td>\n",
              "      <td>0.004640</td>\n",
              "      <td>0.995335</td>\n",
              "      <td>2.428589e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>36454</td>\n",
              "      <td>0.003928</td>\n",
              "      <td>0.961027</td>\n",
              "      <td>3.504479e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>36455</td>\n",
              "      <td>0.983485</td>\n",
              "      <td>0.016515</td>\n",
              "      <td>5.658972e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>36456</td>\n",
              "      <td>0.922564</td>\n",
              "      <td>0.077436</td>\n",
              "      <td>4.039652e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index         0         1             2\n",
              "0     26457  0.066923  0.105767  8.273093e-01\n",
              "1     26458  0.001817  0.998183  6.506126e-08\n",
              "2     26459  0.042324  0.685748  2.719281e-01\n",
              "3     26460  0.117702  0.352815  5.294828e-01\n",
              "4     26461  0.000117  0.999864  1.967510e-05\n",
              "...     ...       ...       ...           ...\n",
              "9995  36452  0.032561  0.967439  7.561642e-07\n",
              "9996  36453  0.004640  0.995335  2.428589e-05\n",
              "9997  36454  0.003928  0.961027  3.504479e-02\n",
              "9998  36455  0.983485  0.016515  5.658972e-14\n",
              "9999  36456  0.922564  0.077436  4.039652e-08\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjgSsiY440bL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}